{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6238341",
   "metadata": {},
   "source": [
    "## Filtering and Triming the Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f7146c",
   "metadata": {},
   "source": [
    "### Filtering\n",
    "\n",
    "Import the required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c812e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import trim_messages,AIMessage,HumanMessage,SystemMessage,AnyMessage,RemoveMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d350ff8",
   "metadata": {},
   "source": [
    "Creating the List of messages as a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e60d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages: list[AnyMessage] = [\n",
    "    SystemMessage(id=\"msg1\", content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(id=\"msg2\", content=\"Hi, can you help me?\"),\n",
    "    AIMessage(id=\"msg3\", content=\"Of course! What do you need?\"),\n",
    "    HumanMessage(id=\"msg4\", content=\"Generate a summary of LangChain.\"),\n",
    "    AIMessage(\n",
    "        id=\"msg5\", content=\"LangChain is a framework for building LLM applications...\"\n",
    "    ),\n",
    "    HumanMessage(id=\"msg6\", content=\"Give me an example of a chain.\"),\n",
    "    AIMessage(id=\"msg7\", content=\"Here is an example chain you can use...\"),\n",
    "    HumanMessage(id=\"msg8\", content=\"Thanks!\"),\n",
    "    AIMessage(id=\"msg9\", content=\"You're welcome!\"),\n",
    "    SystemMessage(id=\"msg10\", content=\"End of conversation.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3c4a73",
   "metadata": {},
   "source": [
    "For Trimming the message you can make use of the `RemoveMessage`class from the `langchain.messages`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6466ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg1'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg2'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg3'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg4'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg5'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg6'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg7'),\n",
       " RemoveMessage(content='', additional_kwargs={}, response_metadata={}, id='msg8')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deleted_message=[RemoveMessage(id=m.id) for m in messages[:-2]]\n",
    "deleted_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ffb4954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.', additional_kwargs={}, response_metadata={}, id='msg1'),\n",
       " HumanMessage(content='Hi, can you help me?', additional_kwargs={}, response_metadata={}, id='msg2'),\n",
       " AIMessage(content='Of course! What do you need?', additional_kwargs={}, response_metadata={}, id='msg3'),\n",
       " HumanMessage(content='Generate a summary of LangChain.', additional_kwargs={}, response_metadata={}, id='msg4'),\n",
       " AIMessage(content='LangChain is a framework for building LLM applications...', additional_kwargs={}, response_metadata={}, id='msg5'),\n",
       " HumanMessage(content='Give me an example of a chain.', additional_kwargs={}, response_metadata={}, id='msg6'),\n",
       " AIMessage(content='Here is an example chain you can use...', additional_kwargs={}, response_metadata={}, id='msg7'),\n",
       " HumanMessage(content='Thanks!', additional_kwargs={}, response_metadata={}, id='msg8'),\n",
       " AIMessage(content=\"You're welcome!\", additional_kwargs={}, response_metadata={}, id='msg9'),\n",
       " SystemMessage(content='End of conversation.', additional_kwargs={}, response_metadata={}, id='msg10')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637469e",
   "metadata": {},
   "source": [
    "As you can see the messages is not deleted to work it wiht we need the Nodes. with `add_messages` which removes the message\n",
    "\n",
    "Lets create a simple graph without calling LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f7a984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState, StateGraph,START,END\n",
    "\n",
    "\n",
    "def filter_message(state: MessagesState) -> MessagesState:\n",
    "    return {\"messages\": [RemoveMessage(id=m.id) for m in messages[:-2]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3e2c89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"filter\",filter_message)\n",
    "graph.add_edge(START,\"filter\")\n",
    "graph.add_edge(\"filter\",END)\n",
    "\n",
    "agent=graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aac0a1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content=\"You're welcome!\", additional_kwargs={}, response_metadata={}, id='msg9'),\n",
       "  SystemMessage(content='End of conversation.', additional_kwargs={}, response_metadata={}, id='msg10')]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke({\n",
    "    \"messages\":messages\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54751158",
   "metadata": {},
   "source": [
    "Here you get only the latest messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f9fd7d",
   "metadata": {},
   "source": [
    "### Trimming Messages\n",
    "\n",
    "Previously we Just saw how we can filter the messages. Now we can trim the messages based on some parameter and by strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3595aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "llm=ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07397bd2",
   "metadata": {},
   "source": [
    "Here we passed the LLM model and `max_tokens` to trimmed out the number of tokens. `strategy` available values are `first` and `last`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61621a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Thanks!', additional_kwargs={}, response_metadata={}, id='msg8'),\n",
       " AIMessage(content=\"You're welcome!\", additional_kwargs={}, response_metadata={}, id='msg9'),\n",
       " SystemMessage(content='End of conversation.', additional_kwargs={}, response_metadata={}, id='msg10')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.messages import trim_messages\n",
    "\n",
    "trim_messages(\n",
    "    messages,\n",
    "    max_tokens=20,\n",
    "    token_counter=llm,\n",
    "    strategy=\"last\",\n",
    "    start_on=\"human\"   \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a4d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langgraph Tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
