{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002c67d9",
   "metadata": {},
   "source": [
    "## Long Term Memory - Memory Store\n",
    "\n",
    "Storing the Memory of the users for long term using the Langgraph Store API\n",
    "\n",
    "LangGraph stores long-term memories as JSON documents in a store. Each memory is organized under a custom namespace (similar to a folder) and a distinct key (like a file name). Namespaces often include user or org IDs or other labels that makes it easier to organize information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80eb3e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph,START,END\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "from langgraph.store.base import BaseStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1196ab",
   "metadata": {},
   "source": [
    "Create the Store with Sqlite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809d29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlite3 import Connection\n",
    "\n",
    "connection: Connection = sqlite3.connect(\"store.db\",check_same_thread=False,isolation_level=None)\n",
    "# Initialize the SQLite store\n",
    "store= SqliteStore(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196112f5",
   "metadata": {},
   "source": [
    "When storing objects (e.g., memories) in the Store, we provide:\n",
    "\n",
    "- The namespace for the object, a tuple (similar to directories)\n",
    "- the object key (similar to filenames)\n",
    "- the object value (similar to file contents)\n",
    "\n",
    "We use the put method to save an object to the store by namespace and key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e7808ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = '12'\n",
    "namespace_for_memory = (\n",
    "    user_id,\n",
    "    \"chat_memory\",\n",
    ")  # Tuple representing user-specific namespace\n",
    "key = \"conversation_1\"  # Unique key for storing in the store\n",
    "value = {\"food\": \"Pizza\", \"name\": \"John Doe\"}  # Data to be stored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67367337",
   "metadata": {},
   "source": [
    "Store in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f15f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put(namespace_for_memory,key,value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04857e82",
   "metadata": {},
   "source": [
    "Searching or getting the list of the namespace present in the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3038c3a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(namespace=['12', 'chat_memory'], key='conversation_1', value={'food': 'Pizza', 'name': 'John Doe'}, created_at='2025-12-02T22:52:40', updated_at='2025-12-02T22:52:40')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.get(namespace_for_memory,key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d43a288",
   "metadata": {},
   "source": [
    "List the Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08acdd81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'chat_memory'), ('12', 'chat_memory')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.list_namespaces()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7532218",
   "metadata": {},
   "source": [
    "Search the values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4f24fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Item(namespace=['12', 'chat_memory'], key='conversation_1', value={'food': 'Pizza', 'name': 'John Doe'}, created_at='2025-12-02T22:52:40', updated_at='2025-12-02T22:52:40', score=None)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.search(namespace_for_memory,query=\"food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85792623",
   "metadata": {},
   "source": [
    "### Chatbot with Long-Term Memory\n",
    "\n",
    "Creating the Instance of the LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26310abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\", temperature=0, include_thoughts=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b3c34e",
   "metadata": {},
   "source": [
    "Creating the simple Converstation Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7347026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_assistant=\"\"\"\n",
    "You are a helpful assistant that helps users with their questions. If you have the details or memory regarding the user, use that to answer the question.\n",
    "Here is the Memory: {memory}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "system_prompt_gather=\"\"\"\n",
    "You are an assistant that helps gather information about the user to store in memory, For Personalizing the user experience.\n",
    "Current User Information: {memory}\n",
    "Based on the Chat History, extract the informmation like the below\n",
    "INSTRUCTIONS:\n",
    "1. Review the Chat History Carefully.\n",
    "2. Identify any new information about the user that can be added to the memory, apart from the provided memory. \n",
    "3. format the memory as a clear, bulleted list.\n",
    "4. If no new information is found, return the existing memory as is.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b139da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain.messages import SystemMessage\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"userid\"]\n",
    "\n",
    "    # Retrieve the memory from the store\n",
    "    namespace_for_memory = (\n",
    "        user_id,\n",
    "        \"chat_memory\",\n",
    "    )\n",
    "    key = f\"memory\"\n",
    "    existing_memory = store.get(namespace_for_memory, key)\n",
    "    if existing_memory:\n",
    "        memory_str = existing_memory.value.get(\"memory\")\n",
    "    else:\n",
    "        memory_str = \"No prior memory found.\"\n",
    "\n",
    "    prompt_template = system_prompt_assistant.format(memory=memory_str)\n",
    "    response = llm_model.invoke(\n",
    "        [SystemMessage(content=prompt_template)] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8c595ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    user_id = config[\"configurable\"][\"userid\"]\n",
    "\n",
    "    # Retrieve the memory from the store\n",
    "    namespace_for_memory = (\n",
    "        user_id,\n",
    "        \"chat_memory\",\n",
    "    )\n",
    "    key = f\"memory\"\n",
    "    existing_memory = store.get(namespace_for_memory, key)\n",
    "    if existing_memory:\n",
    "        memory_str = existing_memory.value.get(\"memory\")\n",
    "    else:\n",
    "        memory_str = \"No prior memory found.\"\n",
    "\n",
    "    prompt_template = system_prompt_gather.format(memory=memory_str)\n",
    "    response = llm_model.invoke(\n",
    "        [SystemMessage(content=prompt_template)] + state[\"messages\"]\n",
    "    )\n",
    "    print(response.content)\n",
    "    store.put(namespace_for_memory,key,{\"memory\": response.content})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524232d8",
   "metadata": {},
   "source": [
    "Creating the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14f4ef2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "memory = InMemorySaver()\n",
    "\n",
    "graph = StateGraph(MessagesState)\n",
    "graph.add_node(\"call_model\", call_model)\n",
    "graph.add_node(\"write_memory\", write_memory)\n",
    "\n",
    "graph.add_edge(START, \"call_model\")\n",
    "graph.add_edge(\"call_model\", \"write_memory\")\n",
    "graph.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Passing the Store\n",
    "compiled_graph = graph.compile(store=store, checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1f90ef",
   "metadata": {},
   "source": [
    "Display the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef98d369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display,Image\n",
    "\n",
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee155c",
   "metadata": {},
   "source": [
    "Let's test out these how it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd650428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance, it's great to meet you! I'll remember your name. How can I help you today?\n",
      "- The user's name is Lance.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"userid\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df10013",
   "metadata": {},
   "source": [
    "Let's Check what is stored in the Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d285308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'chat_memory'), ('12', 'chat_memory')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e5c2517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I Stays in the Europe for Study Purposes\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thanks for letting me know, Lance! That's interesting. Studying in Europe sounds like a great experience.\n",
      "\n",
      "Is there anything specific you'd like to discuss about your studies or life in Europe, or anything else I can help you with?\n",
      "Here's the updated user information:\n",
      "\n",
      "*   The user's name is Lance.\n",
      "*   The user lives in Europe for study purposes.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\", \"userid\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I Stays in the Europe for Study Purposes\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "862fd982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item(namespace=['1', 'chat_memory'], key='memory', value={'memory': \"Here's the updated user information:\\n\\n*   The user's name is Lance.\\n*   The user lives in Europe for study purposes.\"}, created_at='2025-12-02T22:59:35', updated_at='2025-12-02T22:59:35')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.get(('1', 'chat_memory'),\"memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1792aaee",
   "metadata": {},
   "source": [
    "Reusing the Memory on our Second Thread as these was the same Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "839ecb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you tell me my name and all my details?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Lance!\n",
      "\n",
      "Here are the details I have for you:\n",
      "\n",
      "*   **Name:** Lance\n",
      "*   **Location:** You live in Europe for study purposes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\", \"userid\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Can you tell me my name and all my details?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in compiled_graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1fb94",
   "metadata": {},
   "source": [
    "## Memory Schema and Complex Structuring\n",
    "\n",
    "In langchain or langgraph when we invoke the model with structured output there is possibility that it might get failed to extract the output, to encounter and solve these issue, langchain team created module named `trustcall` which patch the json output for huge and complex schema. \n",
    "\n",
    "As we know that llm model can't structure the complex schemas, to solve these issue the trustcall module is used to extract the structured output. Let's see that in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815455a",
   "metadata": {},
   "source": [
    "Defining the Complex Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eab21747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class UserProfile(BaseModel):\n",
    "    name: str = Field(description=\"Name of the User\")\n",
    "    location: str = Field(description=\"Location of the User\")\n",
    "    interests: list[str] = Field(description=\"Interests of the User\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53caaf31",
   "metadata": {},
   "source": [
    "However the schema which we have created can be easily converted to structured output by LLM model. \n",
    "\n",
    "Storing these schema into the store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f569cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace=(\"trial\",)\n",
    "key=\"user_profile\"\n",
    "value=UserProfile(name=\"Lance\",location=\"Europe\",interests=[\"Studying\",\"Traveling\"]).model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce3c4ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.put(namespace,key,value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdac7b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 'chat_memory'), ('12', 'chat_memory'), ('trial',)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.list_namespaces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a341883f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Lance', 'location': 'Europe', 'interests': ['Studying', 'Traveling']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store.get(namespace,key).value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086df293",
   "metadata": {},
   "source": [
    "Convert the value to the appropriate Pydantic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca1e4ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(name='Lance', location='Europe', interests=['Studying', 'Traveling'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userprofile = UserProfile.model_validate(store.get(namespace,key).value)\n",
    "userprofile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e586467",
   "metadata": {},
   "source": [
    "Let's try out how trust call is gonna work for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aa9b70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "699c64af",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model_with_schema = llm_model.with_structured_output(UserProfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6d7c15",
   "metadata": {},
   "source": [
    "Create the extractor by passing the LLM Model, tools choice and appropriate tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eee32d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = create_extractor(\n",
    "    llm=llm_model,\n",
    "    tools=[UserProfile],\n",
    "    tool_choice=\"UserProfile\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014dbd36",
   "metadata": {},
   "source": [
    "Creating the Sample Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef6bddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompts = ChatPromptTemplate.from_messages(\n",
    "    messages=[\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Extract the user profile information from the following conversation.\",\n",
    "        ),\n",
    "        (\"human\", \"Hello my name is alice\"),\n",
    "        (\"human\", \"I live in Wonderland and I love adventures.\"),\n",
    "        (\"human\", \"I love to eat cakes and explore new places.\"),\n",
    "        (\"human\", \"but i hate getting lost.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d30c6eb",
   "metadata": {},
   "source": [
    "Invoke the extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "176dab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = prompts.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119faa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'UserProfile', 'arguments': '{\"interests\": [\"adventures\", \"eating cakes\", \"exploring new places\"], \"location\": \"Wonderland\", \"name\": \"alice\"}'}, '__gemini_function_call_thought_signatures__': {'d5eeaebd-c1f0-4858-a75a-e89c54e56317': 'CpoFAXLI2ny1Gc+w66+lWC5AE4TZr6YyyM2Edh/uvE6zI7WRTbe94CLc1cqBC67ATlhApDkr7+qwZkNUpRuah4XsNicjl0iYYz2TdZ9O9a6aucmYbaTkl60dk6aqmsmgBERBosUxRDoONUPwbhAEGdIe5nk59uPN9rIp9DjYNM1HzE4OrhlPo6jnfC0EkjX3SRQVwCULpB6VWfsFXRDB1Igpzv2rv6kIo+Oe+6b3lbj1vRxPr7X0mxDmJJFpoMAYQpKeCPihA+8t5Gx37ML1Vbmxj5cj1RkL0RhxRerEF+loLOKaNRryF60pkgCiLM5JxUU6pkgmqsFk9axUFgaM38AYRndqrXmampGi2f7Er5ZOxa7YRGZsmUmuQcTE12KvKjT9R6vy2i3nkEi6H7fZvvOWGElsJwlgBL5W1ok2EA8jg1xauCruvzuuk4cRxm+VlgWKp2qOtHsuq73bRYNk684LMeyPlH66OcC/QuTeEdLTknNBrpa3/SWJWBixaAQC0pVlsc4QDzreumnyB2YKWKAGVQdckNJS4VO4D7/3zCGz4n+RCboP1NTx9nqnEQMHuiX5HAvCN7pgAJmg5Oi7X5iGEZTyRJzEkphb8jUv3O36RrEms9/IMxHAoLHzo+BZ/RF1s/e8wOmd9JUUFFP9sMXGxvYDddxj8P4xVkA/zBWDqrU6F+KT+kuTNtaCe81KFxDxXLV5eC2Ft/q2CgcmkO2hHEkaPFD3Wu6Oq9XkO1JGWPsPa6gwM2Zpe80/f2nEbeCllMltAbvfZ15QIbl3eXS8dsuvDGkICR/a8ImVilJmWT7euJGVOkNGEMDFQJExf9UTXGUpMDsgoBsC2ePq8Hf29hTon2L0srQ3xcZ3/SXcPpue7D5e7U6MGHMB'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--10dda615-2ff2-4717-9346-58b9acfda000-0', tool_calls=[{'name': 'UserProfile', 'args': {'interests': ['adventures', 'eating cakes', 'exploring new places'], 'location': 'Wonderland', 'name': 'alice'}, 'id': 'd5eeaebd-c1f0-4858-a75a-e89c54e56317', 'type': 'tool_call'}], usage_metadata={'input_tokens': 108, 'output_tokens': 184, 'total_tokens': 292, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 149}})],\n",
       " 'responses': [UserProfile(name='alice', location='Wonderland', interests=['adventures', 'eating cakes', 'exploring new places'])],\n",
       " 'response_metadata': [{'id': 'd5eeaebd-c1f0-4858-a75a-e89c54e56317'}],\n",
       " 'attempts': 1}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from trustcall._base import ExtractionOutputs\n",
    "\n",
    "response: ExtractionOutputs = bound.invoke(value)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f14651db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserProfile(name='alice', location='Wonderland', interests=['adventures', 'eating cakes', 'exploring new places'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['responses'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902058dc",
   "metadata": {},
   "source": [
    "Similar things we can do with the chatbot model we created in previous section with the memory. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langgraph Tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
