{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6c67a9",
   "metadata": {},
   "source": [
    "## Map Reduce\n",
    "\n",
    "In these tutorial we will going to learn about the Map-Reduce. Also how we make use of `Send` api by **Langgraph**.\n",
    "\n",
    "It has two phases:\n",
    "1. **Map** - Break a task into smaller sub-tasks, processing each sub-task in parallel.\n",
    "2. **Reduce** - Aggregate the results across all of the completed, parallelized sub-tasks.\n",
    "\n",
    "Importing the Required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81727ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict\n",
    "from langgraph.types import Send\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ac286",
   "metadata": {},
   "source": [
    "Prompts we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49184e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_prompt = \"\"\"Generate a list of 3 sub-topics that are all related to this overall topic: {topic}.\"\"\"\n",
    "joke_prompt = \"\"\"Generate a joke about {subject}\"\"\"\n",
    "best_joke_prompt = \"\"\"Below are a bunch of jokes about {topic}. Select the best one! Return the ID of the best one, starting 0 as the ID for the first joke. Jokes: \\n\\n  {jokes}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96424e20",
   "metadata": {},
   "source": [
    "LLM Model Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4871d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    include_thoughts=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51295fd",
   "metadata": {},
   "source": [
    "Defining the States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9f83178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Subjects(BaseModel):\n",
    "    subjects: list[str]\n",
    "\n",
    "class BestJoke(BaseModel):\n",
    "    id: int\n",
    "    \n",
    "class OverallState(TypedDict):\n",
    "    topic: str\n",
    "    subjects: list\n",
    "    jokes: Annotated[list, operator.add]\n",
    "    best_selected_joke: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bee5aa",
   "metadata": {},
   "source": [
    "Defining the Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1b2404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topics(state:OverallState)->OverallState:\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langgraph Tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
